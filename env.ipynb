{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from data_Generator.ipynb\n",
      "importing Jupyter notebook from runs.ipynb\n",
      "importing Jupyter notebook from Configuration.ipynb\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import io, os, sys, types\n",
    "from Utils import NotebookFinder\n",
    "from data_Generator import dataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    def __init__(self, **kwargs):\n",
    "        # super(Env, self).__init__(**kwargs)\n",
    "        self.actions = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "        self.n_actions = len(self.actions)\n",
    "        self.n_features = 76\n",
    "        self.flag = 1  # Tag read train data\n",
    "        self.state =\"\"\n",
    "        self.time = 0\n",
    "        self.reward_ = 0\n",
    "        self.countc = 0\n",
    "        self.Kcount = kwargs.get('Kcount')\n",
    "        self.list = dataGenerator(self.flag,self.Kcount)\n",
    "        self.reward_history = []\n",
    "        self.correct_rate = []\n",
    "        self.time_env_state ={\"next\":{},\"current\":{}}\n",
    "        # self.time_env_state = {'current':{\"feature\":0,\"label\":-1}}\n",
    "        self.log = kwargs.get('log', print) # logging function\n",
    "        self.statusPeriod = kwargs.get('statusPeriod', 1) # period at which to report status\n",
    "\n",
    "    def data(self):\n",
    "        Network_data = self.list[self.time]\n",
    "       # print(\"self.time ={} \".format(self.time))\n",
    "        return Network_data\n",
    "\n",
    "    def update_State(self):\n",
    "        self.time_env_state[\"next\"][\"feature\"] = self.data()[0:76]\n",
    "        self.time_env_state[\"next\"][\"label\"] = self.data()[76]\n",
    "        self.time += 1\n",
    "        return self.time_env_state[\"next\"]\n",
    "\n",
    "    def reset(self):\n",
    "        self.time_env_state[\"next\"] = self.update_State()\n",
    "\n",
    "        return self.time_env_state[\"next\"]\n",
    "\n",
    "    def reward(self,action,state):\n",
    "\n",
    "        self.time_env_state[\"current\"] = state\n",
    "        label = self.time_env_state[\"current\"][\"label\"]\n",
    "        if (action == label)and (label == 0):\n",
    "            reward = 1\n",
    "        elif (action == label)and(label==1):\n",
    "            reward = 100\n",
    "        elif (action == label)and(label==2):\n",
    "            reward = 100\n",
    "        elif (action == label)and(label==3):\n",
    "            reward = 100\n",
    "        elif (action == label)and(label==4):\n",
    "            reward = 100\n",
    "        elif (action == label)and(label==5):\n",
    "            reward = 3.21\n",
    "        elif (action == label)and(label==6):\n",
    "            reward = 2.636\n",
    "        elif (action == label)and(label==7):\n",
    "            reward = 100\n",
    "        elif (action == label)and(label==8):\n",
    "            reward = 52.778\n",
    "        elif (action == label)and(label==9):\n",
    "            reward = 71.05\n",
    "        elif (action == label)and(label==10):\n",
    "            reward =72.28\n",
    "        elif (action ==label) and(label==11):\n",
    "            reward = 76.18\n",
    "        elif (action == label)and(label==12):\n",
    "            reward = 1.813\n",
    "        elif (action == label)and(label==13):\n",
    "            reward = 39.91\n",
    "        elif (action == label)and(label==14):\n",
    "            reward = 100\n",
    "        elif (label==0)and(action!=0):\n",
    "            reward = -1\n",
    "        elif (label==1)and(action!=1):\n",
    "            reward = -100\n",
    "        elif (label==2)and(action!=2):\n",
    "            reward = -100\n",
    "        elif (label==3)and(action!=3):\n",
    "            reward = -100\n",
    "        elif (label==4)and(action!=4):\n",
    "            reward = -100\n",
    "        elif (label==5)and(action!=5):\n",
    "            reward = -3.21\n",
    "        elif (label==6)and(action!=6):\n",
    "            reward = -2.636\n",
    "        elif (label==7)and(action!=7):\n",
    "            reward = -100\n",
    "        elif (label==8)and(action!=8):\n",
    "            reward = -52.778\n",
    "        elif (label==9)and(action!=9):\n",
    "            reward = -71.05\n",
    "        elif (label==10)and(action!=10):\n",
    "            reward = -72.28\n",
    "        elif (label==11)and(action!=11):\n",
    "            reward = -76.18\n",
    "        elif (label==12)and(action!=12):\n",
    "            reward = -1.813\n",
    "        elif (label==13)and(action!=13):\n",
    "            reward = -39.91\n",
    "        elif (label==14)and(action!=14):\n",
    "            reward = -100\n",
    "        return reward,label\n",
    "\n",
    "\n",
    "    def step(self,action,state):\n",
    "\n",
    "        value = 0\n",
    "        min_value = np.Inf\n",
    "        action_key = \"\"\n",
    "\n",
    "        #self.log('{}: action {} has min. value {}\\n'.format(self.time, action_key, min_value), period=self.statusPeriod,\n",
    "        #         counter=self.time)\n",
    "       # next_state = action\n",
    "        reward,label = self.reward(action,state)\n",
    "        self.reward_ = reward\n",
    "        self.count_history.append(self.reward_)\n",
    "\n",
    "       # self.correct_rate.append(self.count/(len(self.count_history)))\n",
    "        #print(\"3998888888888reward.time_env_state[current]==={}\".format(state))\n",
    "        #self.state = \\\n",
    "        self.update_State()\n",
    "        self.time_env_state[\"current\"] = state\n",
    "        return  self.time_env_state[\"next\"], reward,label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
