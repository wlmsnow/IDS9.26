{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, sys, types\n",
    "from Utils import NotebookFinder\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "from runs import sim\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import preprocessing\n",
    "import  pandas as pd\n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "global staut_list\n",
    "def Numerical(source_file,handled_file):\n",
    "    data = pd.read_csv(source_file,delimiter=',')\n",
    "\n",
    "    data = data.values\n",
    "    data = data[:,0:79]\n",
    "    list = data[:,0:78]\n",
    "    list = Imputer(missing_values='NaN', strategy='mean', axis=0).fit_transform(list)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    data[:,0:76] = min_max_scaler.fit_transform(list)\n",
    "    data_normal = data[:,0:77]\n",
    "\n",
    "    count = 0\n",
    "    for i in data:\n",
    "\n",
    "        data_normal[count,76] =  handleLabel(i)\n",
    "        count+=1\n",
    "\n",
    "    data_normal = pd.DataFrame(data_normal)\n",
    "    data_normal.to_csv(handled_file,header=0,index = 0)\n",
    "\n",
    "\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleLabel(input):\n",
    "    global staut_list\n",
    "    if input[78] in staut_list:\n",
    "\n",
    "        return find_index(input[78],staut_list)[0]\n",
    "    else:\n",
    "        staut_list.append(input[78])\n",
    "\n",
    "        return find_index(input[78],staut_list)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(x, y):\n",
    "    return [a for a in range(len(y)) if y[a] == x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function Merge.Combine all the data together.\n",
    "\n",
    "# def Merge():\n",
    "#     csv_list = glob.glob('data/*.csv')  # View the number of csv files in the same folder\n",
    "\n",
    "#     print(u'%s CSV files found' % len(csv_list))\n",
    "#     print(u'Processing............')\n",
    "#     for i in csv_list:  # Loop through the csv file in the same folder\n",
    "#         fr = open(i, 'r').read()\n",
    "#         with open('result.csv', 'a') as f:  # Save the result as result.csv\n",
    "#             f.write(fr)\n",
    "#     print(u'The merger is complete!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestSplit(X,test_size=0.3):\n",
    "     X_num=X.shape[0]\n",
    "     train_index=range(X_num)\n",
    "     test_index=[]\n",
    "     test_num=int(X_num*test_size)\n",
    "     for i in range(test_num):\n",
    "          randomIndex=int(np.random.uniform(0,len(train_index)))\n",
    "          test_index.append(train_index[randomIndex])\n",
    "          del train_index[randomIndex]\n",
    "     train=X.ix[train_index] \n",
    "     test=X.ix[test_index]\n",
    "     return train,test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the training and test data. The training data set is train_usual.csv, the label is train.csv,\n",
    "#  the test data set is test_usual.csv, and the label is test.csv.\n",
    "def dataGenerator(flag,count):\n",
    "    if flag == 1:\n",
    "        #data = pd.read_csv(\"datatest.csv\")\n",
    "        data = pd.read_csv(\"datasetSKF/train-%s.csv\"%count)\n",
    "        print(\"datasetSKF/train-%s.csv\"%count)\n",
    "        list = data.values.tolist()\n",
    "    else:\n",
    "        data = pd.read_csv(\"datasetSKF/test-%s.csv\"%count)\n",
    "        print(\"datasetSKF/test-%s.csv\"%count)\n",
    "        list = data.values.tolist()\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(file):\n",
    "    data = pd.read_csv(file)\n",
    "    data = data.values\n",
    "    data = data[:, 0:77]\n",
    "    count  = 0\n",
    "    list = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in data:\n",
    "        # print(i[0])\n",
    "       # print(data[count,76])\n",
    "        print(data[count,0])\n",
    "        list[int(data[count,76])] += 1\n",
    "        count += 1\n",
    "        \n",
    "        #print('count= {} '.format(count))\n",
    "    return count,list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_Generator_label(flag):\n",
    "#     if flag == 1:\n",
    "#         data = pd.read_csv(\"data/train.csv\")\n",
    "#         list = data.values.tolist()\n",
    "#     else:\n",
    "#         data = pd.read_csv(\"data/test.csv\")\n",
    "#         list = data.values.tolist()\n",
    "#     return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_(file):\n",
    "    data = pd.read_csv(file,delimiter=',',encoding='ISO-8859-1')\n",
    "    data = data.values\n",
    "    data = data[:,0:77]\n",
    "    count = 0\n",
    "   \n",
    "    for i in data:\n",
    "        list[data[count,76]] +=1\n",
    "        \n",
    "        count+=1\n",
    "#     for i in range(15):\n",
    "#         if list[i]:\n",
    "#             print(\"标签为{}的数据数量为{}\".format(i,list[i]))\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008089999999999999\n",
      "0.00122\n",
      "0.000816\n",
      "0.0008089999999999999\n",
      "0.0008089999999999999\n",
      "0.00035099999999999997\n",
      "0.00122\n",
      "0.0067599999999999995\n",
      "0.0068200000000000005\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #global staut_list\n",
    "    #global list\n",
    "    #source_file = [\"Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\",\"Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\",\"Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\",\"Friday-WorkingHours-Morning.pcap_ISCX.csv\",\"Tuesday-WorkingHours.pcap_ISCX.csv\",\"Monday-WorkingHours.pcap_ISCX.csv\",\"Wednesday-workingHours.pcap_ISCX.csv\",\"Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\"]\n",
    "    #handled_file =[\"Thursday-WorkingHours-Afternoon-Infilteration_handle.pcap_ISCX.csv\",\"Friday-WorkingHours-Afternoon-DDos_handle.pcap_ISCX.csv\",\"Friday-WorkingHours-Afternoon-PortScan_handle.pcap_ISCX.csv\",\"Friday-WorkingHours-Morning_handle.pcap_ISCX.csv\",\"Tuesday-WorkingHours_handle.pcap_ISCX.csv\",\"Monday-WorkingHours_handle.pcap_ISCX.csv\",\"Wednesday-workingHours_handle.pcap_ISCX.csv\",\"Thursday-WorkingHours-Morning-WebAttacks_handle.pcap_ISCX.csv\"]\n",
    "\n",
    "\n",
    "    # Numerical_1(source_file,handled_file)\n",
    "    #for(s,h)in zip(source_file,handled_file):\n",
    "    #   Numerical_1(s,h)\n",
    "    # Merge()\n",
    "    #     print(s,h)\n",
    "    #     data_Generator(s,h)(\n",
    "    # trainTestSplit()\n",
    "    # preprocess()\n",
    "    Train_file = [\"datasetSKF/train-0.csv\",\"datasetSKF/train-1.csv\",\"datasetSKF/train-2.csv\"]\n",
    "    Test_file = [\"datasetSKF/test-0.csv\",\"datasetSKF/test-1.csv\",\"datasetSKF/test-2.csv\"] \n",
    "    file = \"datatest.csv\"\n",
    "#     for (train,test) in zip(Train_file,Test_file):\n",
    "#         count_Train,list_Train = counter(train)\n",
    "#         count_test,list_test = counter(test)\n",
    "#         print(\"The total amount of data for the training set {} is {}, and the total amount of data for the test set {} is {}\".format(train,count_Train,test,count_test))\n",
    "#         for i in range(15):\n",
    "#             if list_Train[i]:\n",
    "#                 print(\"The number of data in the {} set tag {} is {}\".format(train,i,list_Train[i]))\n",
    "#             if list_test[i]:\n",
    "#                 print(\"The number of data in the {} set labeled {} is {}\".format(test,i,list_test[i]))\n",
    "    count_test,list_test = counter(file)\n",
    "    print(count_test)\n",
    "\n",
    "#import pandas as pd\n",
    "#import os\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    # global staut_list\n",
    "    # staut_list=[]\n",
    "    #\n",
    "    # source_file = [\"Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\"Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\",\"Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\",\"Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\",\"Friday-WorkingHours-Morning.pcap_ISCX.csv\",\"Tuesday-WorkingHours.csv\",\"Monday-WorkingHours.pcap_ISCX.csv\",\"Wednesday-workingHours.pcap_ISCX.csv\"]\n",
    "    # handled_file = [\"Thursday-WorkingHours-Morning-WebAttacks_handle.pcap_ISCX.csv\",\"Thursday-WorkingHours-Afternoon-Infilteration_handle.pcap_ISCX.csv\",\"Friday-WorkingHours-Afternoon-DDos_handle.pcap_ISCX.csv\",\"Friday-WorkingHours-Afternoon-PortScan_handle.pcap_ISCX.csv\",\"Friday-WorkingHours-Morning_handle.pcap_ISCX.csv\",\"Tuesday-WorkingHours_handle.csv\",\"Monday-WorkingHours_handle.pcap_ISCX.csv\",\"Wednesday-workingHours_handle.pcap_ISCX.csv\"]\n",
    "    # for(s,h)in zip(source_file,handled_file):\n",
    "    #     print(s,h)\n",
    "    #     data_Generator(s,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
